# ðŸ§  VibeML

**Tiny ML models in every language. Inspired by [Karpathy's micrograd](https://github.com/karpathy/micrograd).**

No frameworks. No abstractions. Just the raw math.

*Vibe coded with Claude Opus 4.5 for learning & education.*

## Models

### Simple Neural Network
A 2â†’4â†’1 network that learns XOR.

- **Python** (~35 lines): `python3 neural_network.py`
- **Pascal** (~45 lines): `fpc neural_network.pas && ./neural_network`
- **COBOL** (~70 lines): `cobc -x -free neural_network.cob && ./a.out`

### Vanilla Decision Tree
Recursive splitting with Gini impurity.

- **Python** (~60 lines): `python3 decision_tree.py`

### Gradient Boosting Decision Tree
Fit trees to residuals, sum predictions. Powers XGBoost/LightGBM.

- **Python** (~75 lines): `python3 gbdt.py`

## Structure

```
models/
â”œâ”€â”€ simple_neural_network/
â”‚   â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ pascal/
â”‚   â””â”€â”€ cobol/
â”œâ”€â”€ vanilla_decision_tree/
â”‚   â””â”€â”€ python/
â””â”€â”€ gradient_boosting_decision_tree/
    â””â”€â”€ python/
```

## Roadmap

**Models:** Simple NN âœ“ | Vanilla Decision Tree âœ“ | Gradient Boosting âœ“ | Random Forest | KNN | Linear Regression | CNN | RNN | Transformer

**Languages:** Python âœ“ | Pascal âœ“ | COBOL âœ“ | C | Rust | Go | JavaScript | Haskell

## Contributing

1. Pick a model + language
2. Keep it minimal (<100 lines)
3. No ML libraries
4. PR it

## License

Apache 2.0
