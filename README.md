# ðŸ§  VibeML

**Tiny ML models from scratch. Inspired by [Karpathy's micrograd](https://github.com/karpathy/micrograd).**

No frameworks. No abstractions. Just the raw math.

## Goals

ðŸŽ¯ **Vibe Coding** â€” Build ML models through intuition, not boilerplate. Let the code flow.

ðŸ“š **Learning** â€” Understand what's *really* happening inside neural networks, trees, and beyond.

*Vibe coded with Claude Opus 4.5*

## Models

| Category | Model | Run |
|----------|-------|-----|
| **Neural Networks** | | |
| â”” Feedforward | MLP (XOR) | `python3 models/neural_networks/feedforward/mlp/micro/neural_network.py` |
| â”” Convolutional | CNN | `python3 models/neural_networks/convolutional/cnn/micro/cnn.py` |
| â”” Convolutional | Capsule Network | `python3 models/neural_networks/convolutional/capsule/micro/capsule.py` |
| â”” Recurrent | RNN | `python3 models/neural_networks/recurrent/rnn/micro/rnn.py` |
| â”” Graph | GNN | `python3 models/neural_networks/graph/gnn/micro/gnn.py` |
| â”” Generative | VAE | `python3 models/neural_networks/generative/vae/micro/vae.py` |
| **Self-Supervised** | JEPA | `python3 models/self_supervised/jepa/micro/jepa.py` |
| **Tree-Based** | Decision Tree | `python3 models/tree_based/decision_tree/micro/decision_tree.py` |
| **Tree-Based** | Gradient Boosting | `python3 models/tree_based/gradient_boosting/micro/gbdt.py` |
| **Probabilistic** | CRF | `python3 models/probabilistic/crf/micro/crf.py` |
| **Factorization** | FM | `python3 models/factorization/fm/micro/fm.py` |

## Structure

```
models/
â”œâ”€â”€ neural_networks/
â”‚   â”œâ”€â”€ feedforward/
â”‚   â”‚   â””â”€â”€ mlp/
â”‚   â”‚       â”œâ”€â”€ micro/              # From-scratch Python
â”‚   â”‚       â””â”€â”€ other_languages/    # COBOL, Pascal
â”‚   â”œâ”€â”€ convolutional/
â”‚   â”‚   â”œâ”€â”€ cnn/micro/
â”‚   â”‚   â””â”€â”€ capsule/micro/
â”‚   â”œâ”€â”€ recurrent/
â”‚   â”‚   â””â”€â”€ rnn/micro/
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â””â”€â”€ gnn/micro/
â”‚   â””â”€â”€ generative/
â”‚       â””â”€â”€ vae/micro/
â”‚
â”œâ”€â”€ self_supervised/
â”‚   â””â”€â”€ jepa/micro/
â”‚
â”œâ”€â”€ tree_based/
â”‚   â”œâ”€â”€ decision_tree/micro/
â”‚   â””â”€â”€ gradient_boosting/micro/
â”‚
â”œâ”€â”€ probabilistic/
â”‚   â””â”€â”€ crf/micro/
â”‚
â”œâ”€â”€ factorization/
â”‚   â””â”€â”€ fm/micro/
â”‚
â”œâ”€â”€ meta_learning/              # Coming soon: PFN, MAML
â”œâ”€â”€ reinforcement_learning/     # Coming soon: DQN, PPO
â””â”€â”€ techniques/                 # Coming soon: LoRA, Fine-tuning
```

### Folder Convention

- `micro/` â€” From-scratch implementations (NumPy only)
- `torch/` â€” PyTorch implementations (coming later)
- `other_languages/` â€” Non-Python implementations

## Roadmap

**Models:** MLP âœ“ | Decision Tree âœ“ | GBDT âœ“ | RNN âœ“ | CNN âœ“ | Capsule âœ“ | GNN âœ“ | VAE âœ“ | JEPA âœ“ | CRF âœ“ | FM âœ“ | LSTM | Transformer | Word2Vec | Boltzmann | RL

**Categories:** Neural Networks âœ“ | Tree-Based âœ“ | Probabilistic âœ“ | Self-Supervised âœ“ | Meta-Learning | Reinforcement Learning

## Contributing

1. Pick a model + category
2. Keep it minimal (<200 lines for micro/)
3. No ML libraries (NumPy only)
4. Add a README explaining the math
5. PR it

## License

Apache 2.0
